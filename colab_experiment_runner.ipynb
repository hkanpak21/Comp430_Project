{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secure Split Federated Learning Experiment Runner\n",
    "\n",
    "This notebook runs experiments with different configurations and generates a comprehensive report with CSV export."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import subprocess\n",
    "import csv\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Check if running in Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Google Colab: {IN_COLAB}\")\n",
    "\n",
    "# Check for GPU\n",
    "if IN_COLAB:\n",
    "    !nvidia-smi\n",
    "    import torch\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clone the repository\n",
    "if IN_COLAB:\n",
    "    # Assuming the repository is public. Replace with your actual repository URL.\n",
    "    !git clone https://github.com/hkanpak21/Comp430_Project.git\n",
    "    %cd Comp430_Project\n",
    "    \n",
    "    # Install dependencies\n",
    "    !pip install -r requirements.txt\n",
    "    \n",
    "    # If requirements.txt doesn't exist, install likely needed packages\n",
    "    !pip install torch torchvision numpy pandas matplotlib pyyaml tqdm scikit-learn\n",
    "else:\n",
    "    # If running locally, assume we're already in the repo directory\n",
    "    print(\"Running locally - assuming dependencies are already installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Experiment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration from YAML file\"\"\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "def run_experiment(config_path, output_file):\n",
    "    \"\"\"Run an experiment with the given configuration file\"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\nRunning experiment with config: {config_path}\")\n",
    "    \n",
    "    # Command to run the training script\n",
    "    cmd = f\"python experiments/train_secure_sfl.py --config {config_path}\"\n",
    "    \n",
    "    # Capture output\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    output = result.stdout\n",
    "    error = result.stderr\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Extract final accuracy from output - try multiple patterns\n",
    "    final_acc = None\n",
    "    \n",
    "    # Pattern 1: \"Final test accuracy: XX.XX%\"\n",
    "    for line in output.split('\\n'):\n",
    "        if 'Final test accuracy' in line:\n",
    "            try:\n",
    "                final_acc = float(line.split(':')[-1].strip().rstrip('%'))\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Pattern 2: \"Test accuracy: XX.XX%\" (last occurrence)\n",
    "    if final_acc is None:\n",
    "        acc_lines = [line for line in output.split('\\n') if 'Test accuracy' in line]\n",
    "        if acc_lines:\n",
    "            try:\n",
    "                final_acc = float(acc_lines[-1].split(':')[-1].strip().rstrip('%'))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Pattern 3: \"Accuracy: XX.XX%\" (last occurrence)\n",
    "    if final_acc is None:\n",
    "        acc_lines = [line for line in output.split('\\n') if 'Accuracy:' in line]\n",
    "        if acc_lines:\n",
    "            try:\n",
    "                final_acc = float(acc_lines[-1].split(':')[-1].strip().rstrip('%'))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Prepare result summary\n",
    "    config_name = os.path.basename(config_path)\n",
    "    result_summary = f\"\\n{'='*50}\\n\"\n",
    "    result_summary += f\"Config: {config_name}\\n\"\n",
    "    result_summary += f\"Time: {elapsed_time:.2f} seconds\\n\"\n",
    "    \n",
    "    if final_acc is not None:\n",
    "        result_summary += f\"Final Accuracy: {final_acc:.2f}%\\n\"\n",
    "    else:\n",
    "        result_summary += \"Final Accuracy: Not found in output\\n\"\n",
    "        \n",
    "        # Save debug output\n",
    "        debug_file = f\"debug_{config_name}.txt\"\n",
    "        with open(debug_file, 'w') as f:\n",
    "            f.write(f\"STDOUT:\\n{output}\\n\\nSTDERR:\\n{error}\")\n",
    "        result_summary += f\"Debug output saved to: {debug_file}\\n\"\n",
    "    \n",
    "    # Check for errors\n",
    "    if error:\n",
    "        result_summary += f\"\\nErrors:\\n{error}\\n\"\n",
    "    \n",
    "    # Save to output file\n",
    "    with open(output_file, 'a') as f:\n",
    "        f.write(result_summary)\n",
    "    \n",
    "    print(result_summary)\n",
    "    \n",
    "    # Load config details\n",
    "    try:\n",
    "        config = load_config(config_path)\n",
    "    except:\n",
    "        config = {}\n",
    "    \n",
    "    return {\n",
    "        'config_path': config_path,\n",
    "        'config_name': config_name,\n",
    "        'final_acc': final_acc,\n",
    "        'elapsed_time': elapsed_time,\n",
    "        'success': final_acc is not None and not error,\n",
    "        'error': error if error else None,\n",
    "        'model': config.get('model', 'Unknown'),\n",
    "        'optimizer': config.get('optimizer', 'Unknown'),\n",
    "        'cut_layer': config.get('cut_layer', 'Unknown'),\n",
    "        'lr': config.get('lr', 'Unknown'),\n",
    "        'batch_size': config.get('batch_size', 'Unknown'),\n",
    "        'num_clients': config.get('num_clients', 'Unknown'),\n",
    "        'num_rounds': config.get('num_rounds', 'Unknown'),\n",
    "        'initial_sigma': config.get('dp_noise', {}).get('initial_sigma', 'Unknown'),\n",
    "        'noise_multiplier': config.get('dp_noise', {}).get('noise_multiplier', 'Unknown')\n",
    "    }\n",
    "\n",
    "def export_to_csv(results, csv_file):\n",
    "    \"\"\"Export results to CSV file\"\"\"\n",
    "    fieldnames = [\n",
    "        'config_name', 'model', 'optimizer', 'cut_layer', 'lr', 'batch_size', \n",
    "        'num_clients', 'num_rounds', 'initial_sigma', 'noise_multiplier',\n",
    "        'final_acc', 'elapsed_time', 'success'\n",
    "    ]\n",
    "    \n",
    "    with open(csv_file, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for result in results:\n",
    "            # Filter to only include the fields we want\n",
    "            filtered_result = {k: v for k, v in result.items() if k in fieldnames}\n",
    "            writer.writerow(filtered_result)\n",
    "    \n",
    "    print(f\"Results exported to {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set up experiment parameters\n",
    "config_filter = \"exp_\"  # Filter to only run our experimental configs\n",
    "report_file = \"experiment_results.txt\"\n",
    "csv_file = \"experiment_results.csv\"\n",
    "\n",
    "# Get all config files\n",
    "config_files = glob.glob(\"configs/*.yaml\")\n",
    "\n",
    "# Apply filter if provided\n",
    "if config_filter:\n",
    "    config_files = [f for f in config_files if config_filter in f]\n",
    "\n",
    "print(f\"Found {len(config_files)} configuration files to test\")\n",
    "\n",
    "# Create report file\n",
    "with open(report_file, 'w') as f:\n",
    "    f.write(f\"# Secure SFL Experiment Report\\n\")\n",
    "    f.write(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "\n",
    "# Run experiments\n",
    "results = []\n",
    "for config_path in tqdm(sorted(config_files), desc=\"Running experiments\"):\n",
    "    result = run_experiment(config_path, report_file)\n",
    "    results.append(result)\n",
    "\n",
    "# Export results to CSV\n",
    "export_to_csv(results, csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate summary\n",
    "successful_results = [r for r in results if r['success']]\n",
    "\n",
    "with open(report_file, 'a') as f:\n",
    "    f.write(f\"\\n\\n## Summary of Results\\n\\n\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    f.write(f\"### Overall Statistics\\n\\n\")\n",
    "    f.write(f\"Total experiments run: {len(results)}\\n\")\n",
    "    f.write(f\"Successful experiments: {len(successful_results)}\\n\")\n",
    "    f.write(f\"Success rate: {len(successful_results)/len(results)*100:.2f}%\\n\\n\")\n",
    "    \n",
    "    # Best configurations\n",
    "    f.write(f\"### Top Configurations by Accuracy\\n\\n\")\n",
    "    best_configs = sorted(successful_results, key=lambda x: x['final_acc'] if x['final_acc'] else 0, reverse=True)\n",
    "    \n",
    "    f.write(f\"| Rank | Configuration | Model | Cut Layer | Optimizer | LR | Batch Size | Clients | Accuracy (%) | Runtime (s) |\\n\")\n",
    "    f.write(f\"|------|--------------|-------|-----------|-----------|----|-----------|---------|--------------|--------------| \\n\")\n",
    "    \n",
    "    for i, result in enumerate(best_configs, 1):\n",
    "        f.write(f\"| {i} | {result['config_name']} | {result['model']} | {result['cut_layer']} | {result['optimizer']} | {result['lr']} | {result['batch_size']} | {result['num_clients']} | {result['final_acc']:.2f} | {result['elapsed_time']:.2f} |\\n\")\n",
    "\n",
    "print(f\"\\nExperiment report generated: {report_file}\")\n",
    "print(f\"Results exported to CSV: {csv_file}\")\n",
    "print(f\"Total experiments: {len(results)}\")\n",
    "print(f\"Successful experiments: {len(successful_results)}\")\n",
    "\n",
    "if successful_results:\n",
    "    best_result = max(successful_results, key=lambda x: x['final_acc'] if x['final_acc'] else 0)\n",
    "    print(f\"\\nBest configuration: {best_result['config_name']}\")\n",
    "    print(f\"Best accuracy: {best_result['final_acc']:.2f}%\")\n",
    "    print(f\"Model: {best_result['model']}, Cut Layer: {best_result['cut_layer']}\")\n",
    "    print(f\"Optimizer: {best_result['optimizer']}, Learning Rate: {best_result['lr']}\")\n",
    "    print(f\"Batch Size: {best_result['batch_size']}, Clients: {best_result['num_clients']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load results into a DataFrame\n",
    "df = pd.DataFrame(successful_results)\n",
    "\n",
    "# Convert columns to appropriate types\n",
    "df['final_acc'] = pd.to_numeric(df['final_acc'], errors='coerce')\n",
    "df['cut_layer'] = pd.to_numeric(df['cut_layer'], errors='coerce')\n",
    "df['lr'] = pd.to_numeric(df['lr'], errors='coerce')\n",
    "df['batch_size'] = pd.to_numeric(df['batch_size'], errors='coerce')\n",
    "df['num_clients'] = pd.to_numeric(df['num_clients'], errors='coerce')\n",
    "\n",
    "# Set up the figure size\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Create visualizations\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.barplot(x='model', y='final_acc', data=df)\n",
    "plt.title('Accuracy by Model Type')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.barplot(x='cut_layer', y='final_acc', data=df)\n",
    "plt.title('Accuracy by Cut Layer')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.barplot(x='batch_size', y='final_acc', data=df)\n",
    "plt.title('Accuracy by Batch Size')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.barplot(x='num_clients', y='final_acc', data=df)\n",
    "plt.title('Accuracy by Number of Clients')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('experiment_results_visualization.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    \n",
    "    # Download CSV results\n",
    "    files.download(csv_file)\n",
    "    \n",
    "    # Download report\n",
    "    files.download(report_file)\n",
    "    \n",
    "    # Download visualization\n",
    "    files.download('experiment_results_visualization.png')\n",
    "    \n",
    "    print(\"Files ready for download\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
